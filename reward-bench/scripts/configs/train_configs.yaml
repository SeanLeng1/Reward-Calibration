# This file contains default training parameters assuming access to A100-80GBs
allenai/tulu-2-7b:
  model: 'allenai/tulu-2-7b'
  tokenizer: 'allenai/tulu-2-7b'
  chat_template: 'tulu'
  num_gpus: 4
  total_batch_size: 128
  batch_size_per_gpu: 2
  max_seq_len: 1024
  use_flash_attn: True
  bf16: True
meta-llama/Llama-2-7b-chat-hf:
  model: 'meta-llama/Llama-2-7b-chat-hf'
  tokenizer: 'meta-llama/Llama-2-7b-chat-hf'
  chat_template: 'llama-2'
  num_gpus: 4
  total_batch_size: 128
  batch_size_per_gpu: 2
  max_seq_len: 1024
  use_flash_attn: True
  bf16: True
TinyLlama/TinyLlama-1.1B-Chat-v1.0:
  model: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'
  tokenizer: 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'
  chat_template: 'llama-2'
  num_gpus: 2
  total_batch_size: 128
  batch_size_per_gpu: 16
  max_seq_len: 1024
  use_flash_attn: True
  bf16: True